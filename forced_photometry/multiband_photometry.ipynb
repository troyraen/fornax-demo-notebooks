{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated multiband forced photometry on large datasets\n",
    "\n",
    "### Summary:\n",
    "This code performs photometry in an automated fashion at all locations in an input catalog on 4 bands of IRAC data from IRSA and 2 bands of Galex data from MAST.  The resulting catalog is then cross-matched with a Chandra catalog from HEASARC to generate a multiband catalog to facilitate galaxy evolution studies.\n",
    "\n",
    "The code will run on 2 different science platforms and makes full use of multiple processors to optimize run time on large datasets.\n",
    "\n",
    "### Input:\n",
    "- RA and DEC within COSMOS catalog\n",
    "- desired catalog radius in arcminutes\n",
    "- mosaics of that region for IRAC and Galex\n",
    "\n",
    "### Output:\n",
    "- merged, multiband, science ready pandas dataframe\n",
    "- IRAC color color plot for identifying interesting populations\n",
    "\n",
    "### Authors:\n",
    "Jessica Krick  \n",
    "David Shupe  \n",
    "Marziye JafariYazani  \n",
    "Brigitta Sipocz  \n",
    "Vandana Desai  \n",
    "Steve Groom  \n",
    "\n",
    "### Acknowledgements:\n",
    "Nyland et al. 2017 for the workflow of the code  \n",
    "Lang et al. ??? for the Tractor  \n",
    "Salvato et al. 2018 for nway  \n",
    "Laigle et al. 2016 for COSMOS2015  \n",
    "IRSA, MAST, HEASARC  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary cell to ensure all dependencies are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard lib imports\n",
    "\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "import sys\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Third party imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "\n",
    "from tractor import (\n",
    "    Tractor,\n",
    "    PointSource,\n",
    "    PixPos,\n",
    "    Flux,\n",
    "    PixelizedPSF,\n",
    "    NullWCS,\n",
    "    NullPhotoCal,\n",
    "    ConstantSky,\n",
    "    Image,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import mpld3\n",
    "\n",
    "from firefly_client import FireflyClient\n",
    "import firefly_client.plot as ffplt\n",
    "\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.wcs import WCS\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "from astroquery.heasarc import Heasarc\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Local code imports\n",
    "sys.path.append(\"../code/\")\n",
    "\n",
    "from determine_source_type import determine_source_type\n",
    "from extract_cutout import extract_cutout\n",
    "from find_nconfsources import find_nconfsources\n",
    "from display_images import display_images\n",
    "from plot_SED import plot_SED\n",
    "from nway_write_header import nway_write_header\n",
    "\n",
    "# from prepare_prf import prepare_prf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull initial catalog from IRSA\n",
    "- Automatically set up a catalog with ra, dec, photometric redshifts, fiducial band fluxes, & probability that it is a star  \n",
    "- Catalog we are using is COSMOS2015 (Laigle et al. 2016)  \n",
    "- Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a COSMOS catalog from IRSA using astroquery\n",
    "\n",
    "# make sure the archive isn't limiting our search\n",
    "# default values of row_limit are often much lower than what we might want\n",
    "Irsa.ROW_LIMIT = 3e6\n",
    "Irsa.TIMEOUT = 600\n",
    "\n",
    "\n",
    "# what is the central RA and DEC of the desired catalog\n",
    "coords = SkyCoord(\"150.01d 2.2d\", frame=\"icrs\")  # COSMOS center acording to Simbad\n",
    "\n",
    "# how large is the search radius, in arcmin\n",
    "radius = (\n",
    "    15 * u.arcmin\n",
    ")  # full COSMOS is 48arcmin  #was testing with smaller like 3 or 15\n",
    "\n",
    "# use Astroquery to get the catalog\n",
    "# specify only select columns to limit the size of the catalog\n",
    "cosmos_table = Irsa.query_region(\n",
    "    coords,\n",
    "    catalog=\"cosmos2015\",\n",
    "    radius=radius,\n",
    "    selcols=\"ra,dec,id,Ks_FLUX_APER2,Ks_FLUXERR_APER2, PHOTOZ, SPLASH_1_MAG,SPLASH_1_MAGERR, SPLASH_1_FLUX,SPLASH_1_FLUX_ERR,SPLASH_2_FLUX, SPLASH_2_FLUX_ERR,SPLASH_3_FLUX,SPLASH_3_FLUX_ERR,SPLASH_4_FLUX, SPLASH_4_FLUX_ERR, FLUX_GALEX_NUV,FLUX_GALEX_FUV,FLUX_CHANDRA_05_2,FLUX_CHANDRA_2_10, FLUX_CHANDRA_05_10,ID_CHANDRA09 , type,r_MAG_AUTO,r_MAGERR_AUTO, FLUX_24, FLUXERR_24, MAG_GALEX_NUV, MAGERR_GALEX_NUV,MAG_GALEX_FUV, MAGERR_GALEX_FUV\",\n",
    ")\n",
    "\n",
    "# select those rows with either chandra fluxes or Galex NUV fluxes\n",
    "# this limits the catalog size for testing\n",
    "# ccosmos_table = cosmos_table[(cosmos_table['flux_chandra_05_10']> 0) | (cosmos_table['flux_galex_fuv'] > 0)]\n",
    "# ccosmos_table = cosmos_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull image datasets from the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the fornax cloud access API to obtain the IRAC data from the IRSA S3 bucket. \n",
    "\n",
    "Details here may change as the prototype code is being added to the appropriate libraries, as well as the data holding to the appropriate NGAP storage as opposed to IRSA resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary solution\n",
    "# This relies on the assumption that https://github.com/fornax-navo/fornax-cloud-access-API is being cloned to this environment.\n",
    "# If it's not, then run a ``git clone https://github.com/fornax-navo/fornax-cloud-access-API --depth=1`` from a terminal at the highest directory root.\n",
    "\n",
    "# Until https://github.com/fornax-navo/fornax-cloud-access-API/pull/4 is merged clone the fork instead:\n",
    "# ``git clone https://github.com/bsipocz/fornax-cloud-access-API --depth=1 -b handler_return``\n",
    "\n",
    "sys.path.append(\"../../fornax-cloud-access-API\")\n",
    "\n",
    "import pyvo\n",
    "import fornax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the COSMOS address from the registry to follow PyVO user case approach. We could hardwire it.\n",
    "image_services = pyvo.regsearch(servicetype=\"image\")\n",
    "irsa_cosmos = [s for s in image_services if \"irsa\" in s.ivoid and \"cosmos\" in s.ivoid][\n",
    "    0\n",
    "]\n",
    "\n",
    "# The search returns 11191 entries, but unfortunately we cannot really filter efficiently in the query\n",
    "# itself (https://irsa.ipac.caltech.edu/applications/Atlas/AtlasProgramInterface.html#inputparam)\n",
    "# to get only the Spitzer IRAC results from COSMOS as a mission. We will do the filtering in a next step before download.\n",
    "cosmos_results = irsa_cosmos.search(coords).to_table()\n",
    "\n",
    "spitzer = cosmos_results[cosmos_results[\"dataset\"] == \"IRAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily add the cloud_access metadata to the Atlas response.\n",
    "# This dataset has limited acces, thus 'region' should be used instead of 'open'.\n",
    "# S3 access should be available from the daskhub and those who has their IRSA token set up.\n",
    "\n",
    "fname = spitzer[\"fname\"]\n",
    "spitzer[\"cloud_access\"] = [\n",
    "    (\n",
    "        f'{{\"aws\": {{ \"bucket\": \"irsa-mast-tike-spitzer-data\",'\n",
    "        f'             \"region\": \"us-east-1\",'\n",
    "        f'             \"access\": \"region\",'\n",
    "        f'             \"path\": \"data/COSMOS/{fn}\" }} }}'\n",
    "    )\n",
    "    for fn in fname\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding function to download multiple files using the fornax API.\n",
    "# Requires https://github.com/fornax-navo/fornax-cloud-access-API/pull/4\n",
    "def fornax_download(\n",
    "    data_table,\n",
    "    data_directory=\"../data\",\n",
    "    access_url_column=\"access_url\",\n",
    "    fname_filter=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    working_dir = os.getcwd()\n",
    "\n",
    "    os.chdir(data_directory)\n",
    "    for row in data_table:\n",
    "        if fname_filter is not None and fname_filter not in row[\"fname\"]:\n",
    "            continue\n",
    "        handler = fornax.get_data_product(\n",
    "            row, \"aws\", access_url_column=access_url_column, verbose=verbose\n",
    "        )\n",
    "        handler.download()\n",
    "\n",
    "    os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fornax_download(\n",
    "    spitzer,\n",
    "    access_url_column=\"sia_url\",\n",
    "    fname_filter=\"go2_sci\",\n",
    "    data_directory=\"../data/IRAC\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use astroquery.mast to obtain Galex from the MAST archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Galex mosaic of COSMOS is broken into 4 seperate images\n",
    "# need to know which Galex image the targets are nearest to.\n",
    "# make a new column in dataframe which figures this out\n",
    "\n",
    "# four centers for 1, 2, 3, 4 are\n",
    "ra_center = [150.369, 150.369, 149.869, 149.869]\n",
    "dec_center = [2.45583, 1.95583, 2.45583, 1.95583]\n",
    "\n",
    "# ra_center = 150.369\n",
    "# dec_center = 2.45583\n",
    "galex = SkyCoord(ra=ra_center * u.degree, dec=dec_center * u.degree)\n",
    "catalog = SkyCoord(ra=cosmos_table[\"ra\"], dec=cosmos_table[\"dec\"])\n",
    "# idx, d2d, d3d = match_coordinates_sky(galex, catalog)  #only finds the nearest one\n",
    "# idx, d2d, d3d = galex.match_to_catalog_sky(catalog)  #only finds the nearest one\n",
    "\n",
    "cosmos_table[\"COSMOS_01\"] = galex[0].separation(catalog)\n",
    "cosmos_table[\"COSMOS_02\"] = galex[1].separation(catalog)\n",
    "cosmos_table[\"COSMOS_03\"] = galex[2].separation(catalog)\n",
    "cosmos_table[\"COSMOS_04\"] = galex[3].separation(catalog)\n",
    "\n",
    "# convert to pandas\n",
    "df = cosmos_table.to_pandas()\n",
    "\n",
    "# which row has the minimum value of distance to the galex images\n",
    "df[\"galex_image\"] = df[[\"COSMOS_01\", \"COSMOS_02\", \"COSMOS_03\", \"COSMOS_04\"]].idxmin(\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 76k with 15arcmin diameter IRAC images\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull Galex mosaics from MAST\n",
    "# Get the observations you want\n",
    "in_coordinates = \"150.01 2.20\"\n",
    "observations = Observations.query_criteria(\n",
    "    coordinates=in_coordinates, instrument_name=\"GALEX\"\n",
    ")\n",
    "\n",
    "filtered_observations = observations[(observations[\"t_exptime\"] > 40000.0)]\n",
    "\n",
    "# Get the products for these observations\n",
    "products = Observations.get_product_list(filtered_observations)\n",
    "\n",
    "# Filter the products so we only download SCIENCE products\n",
    "filtered_products = Observations.filter_products(\n",
    "    products,\n",
    "    productType=\"SCIENCE\",\n",
    "    productGroupDescription=\"Minimum Recommended Products\",\n",
    ")\n",
    "\n",
    "# Enable cloud access\n",
    "Observations.enable_cloud_dataset(provider=\"AWS\")\n",
    "\n",
    "# uncomment to actually download the data\n",
    "# Download filtered products\n",
    "# Observations.download_products(filtered_products, cloud_only=True, download_dir = '../data/Galex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to get the GALEX skybg fits files in addition to the mosaics\n",
    "# don't have this working yet, instead pull these files manually\n",
    "# get observations\n",
    "in_coordinates = \"150.01 2.20\"\n",
    "observations = Observations.query_criteria(\n",
    "    coordinates=in_coordinates, instrument_name=\"GALEX\"\n",
    ")\n",
    "\n",
    "# get products of said observations (i'm just doing the first one)\n",
    "products = Observations.get_product_list(observations)\n",
    "\n",
    "# filtering for skybg\n",
    "skybg_products = []\n",
    "# for irow, row in enumerate(products['dataURI']):\n",
    "for row in products[\"dataURI\"]:\n",
    "    if \"COSMOS_01-fd-skybg\" in row:\n",
    "        print(row)\n",
    "        #      skybg_products.append(products[irow])\n",
    "        skybg_products.append(str(row))\n",
    "        # Observations.download_file(skybg_products, cloud_only=True, local_path = '../data/Galex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there aren't any troublesome rows in the catalog\n",
    "# are there missing values in any rows?\n",
    "df.isna().sum()\n",
    "\n",
    "# don't mind that there are missing values for some of the fluxes\n",
    "# The rest of the rows are complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of curiosity how many of each type of source are in this catalog\n",
    "# Type: 0 = galaxy, 1 = star, 2 = X-ray source, -9 is failure to fit\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup to run forced photometry\n",
    "- initialize data frame columsn to hold the results\n",
    "- supress debugging output of tractor \n",
    "- build necessary arrays for multiple bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####purely for testing\n",
    "# df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns in data frame for photometry results\n",
    "df[\n",
    "    [\n",
    "        \"ch1flux\",\n",
    "        \"ch1flux_unc\",\n",
    "        \"ch2flux\",\n",
    "        \"ch2flux_unc\",\n",
    "        \"ch3flux\",\n",
    "        \"ch3flux_unc\",\n",
    "        \"ch4flux\",\n",
    "        \"ch4flux_unc\",\n",
    "        \"ch5flux\",\n",
    "        \"ch5flux_unc\",\n",
    "        \"ch6flux\",\n",
    "        \"ch6flux_unc\",\n",
    "    ]\n",
    "] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup to supress output of tractor\n",
    "# seems to be the only way to make it be quiet and not output every step of optimization\n",
    "# https://stackoverflow.com/questions/2125702/how-to-suppress-console-output-in-python\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters needed for the next function\n",
    "\n",
    "# IRAC\n",
    "irac_fluxconversion = (\n",
    "    (1e12) / (4.254517e10) * (0.6) * (0.6)\n",
    ")  # convert tractor result to microjanskies\n",
    "mosaic_pix_scale_irac = 0.6\n",
    "cutout_width_irac = 10  # in arcseconds, taken from Nyland et al. 2017\n",
    "bkg_method_irac = \"image\"  # use the science image itself\n",
    "\n",
    "# Galex\n",
    "cutout_width_GALEX = 40\n",
    "GALEX_nuv_fluxconversion = (\n",
    "    3.373e1  # uJy  fudging this to make the numbers bigger for plotting later\n",
    ")\n",
    "GALEX_fuv_fluxconversion = (\n",
    "    1.076e2  # uJy fudging this to make the numbers bigger for plotting later\n",
    ")\n",
    "mosaic_pix_scale_GALEX = 1.5\n",
    "bkg_method_GALEX = \"skybg\"  # use the GALEX provided skybg fits file\n",
    "\n",
    "\n",
    "cutout_width_list = [\n",
    "    cutout_width_irac,\n",
    "    cutout_width_irac,\n",
    "    cutout_width_irac,\n",
    "    cutout_width_irac,\n",
    "    cutout_width_GALEX,\n",
    "    cutout_width_GALEX,\n",
    "]\n",
    "flux_conv_list = [\n",
    "    irac_fluxconversion,\n",
    "    irac_fluxconversion,\n",
    "    irac_fluxconversion,\n",
    "    irac_fluxconversion,\n",
    "    GALEX_nuv_fluxconversion,\n",
    "    GALEX_fuv_fluxconversion,\n",
    "]\n",
    "mosaic_pix_scale_list = [\n",
    "    mosaic_pix_scale_irac,\n",
    "    mosaic_pix_scale_irac,\n",
    "    mosaic_pix_scale_irac,\n",
    "    mosaic_pix_scale_irac,\n",
    "    mosaic_pix_scale_GALEX,\n",
    "    mosaic_pix_scale_GALEX,\n",
    "]\n",
    "background_method_list = [\n",
    "    bkg_method_irac,\n",
    "    bkg_method_irac,\n",
    "    bkg_method_irac,\n",
    "    bkg_method_irac,\n",
    "    bkg_method_GALEX,\n",
    "    bkg_method_GALEX,\n",
    "]\n",
    "\n",
    "# GALEX MASTER PSFs\n",
    "prf_nuv = fits.open(\"../data/Galex/PSFnuv_faint.fits\")[0].data\n",
    "prf_fuv = fits.open(\"../data/Galex/PSFfuv.fits\")[0].data\n",
    "prf_nuv = prf_nuv[0:119, 0:119]\n",
    "prf_fuv = prf_fuv[0:119, 0:119]\n",
    "# these are much larger than the cutouts we are using, so only keep the central region which is the size of our cutouts\n",
    "ngalex_pix = cutout_width_GALEX / mosaic_pix_scale_GALEX\n",
    "prf_cen = int(60)\n",
    "prf_nuv = prf_nuv[\n",
    "    (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "    (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "]\n",
    "prf_fuv = prf_fuv[\n",
    "    (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "    (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "]\n",
    "\n",
    "\n",
    "# set up prfs for each channel\n",
    "prfs = [\n",
    "    fits.open(\"../data/IRAC/PRF_IRAC_ch1.fits\")[0].data,\n",
    "    fits.open(\"../data/IRAC/PRF_IRAC_ch2.fits\")[0].data,\n",
    "    fits.open(\"../data/IRAC/PRF_IRAC_ch3.fits\")[0].data,\n",
    "    fits.open(\"../data/IRAC/PRF_IRAC_ch4.fits\")[0].data,\n",
    "    prf_nuv,\n",
    "    prf_fuv,\n",
    "]\n",
    "\n",
    "# set up mosaics for each channel\n",
    "# for now we are manually creating these mosaics using coords above and\n",
    "# https://irsa.ipac.caltech.edu/data/COSMOS/index_cutouts.html\n",
    "# https://irsa.ipac.caltech.edu/data/COSMOS/\n",
    "# infiles = ['../data/IRAC/COSMOS_IRAC_ch1_mosaic_15arcmin.fits',\n",
    "#           '../data/IRAC/COSMOS_IRAC_ch2_mosaic_15arcmin.fits',\n",
    "#           '../data/IRAC/COSMOS_IRAC_ch3_mosaic_15arcmin.fits',\n",
    "#           '../data/IRAC/COSMOS_IRAC_ch4_mosaic_15arcmin.fits',\n",
    "#           '../data/Galex/COSMOS_galex_nuv_mosaic_15arcmin.fits',\n",
    "#           '../data/Galex/COSMOS_galex_fuv_mosaic_15arcmin.fits']\n",
    "\n",
    "# setup for full field of view\n",
    "infiles = [\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch1_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch2_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch3_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch4_mosaic.fits\",\n",
    "    \"../data/Galex/COSMOS_01-nd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_01-fd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_02-nd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_02-fd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_03-nd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_03-fd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_04-nd-int.fits\",\n",
    "    \"../data/Galex/COSMOS_04-fd-int.fits\",\n",
    "]\n",
    "\n",
    "skybgfiles = [\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch1_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch2_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch3_mosaic.fits\",\n",
    "    \"../data/IRAC/COSMOS_IRAC_ch4_mosaic.fits\",\n",
    "    \"../data/Galex/COSMOS_01-nd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_01-fd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_02-nd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_02-fd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_03-nd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_03-fd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_04-nd-skybg.fits\",\n",
    "    \"../data/Galex/COSMOS_04-fd-skybg.fits\",\n",
    "]\n",
    "\n",
    "# 3 arcmin radius mosaics\n",
    "#'../data/IRAC/COSMOS_irac_ch1_mosaic_recenter.fits',\n",
    "#           '../data/IRAC/COSMOS_irac_ch2_mosaic_recenter.fits',\n",
    "#           '../data/IRAC/COSMOS_irac_ch3_mosaic_recenter.fits',\n",
    "#           '../data/IRAC/COSMOS_irac_ch4_mosaic_recenter.fits',\n",
    "#           '../data/Galex/0001_150.01000000_2.20000000_COSMOS_01-nd-int.fits',\n",
    "#           '../data/Galex/0001_150.01000000_2.20000000_COSMOS_01-fd-int.fits']\n",
    "\n",
    "\n",
    "# read in those mosaics\n",
    "hdulists = [\n",
    "    fits.open(infiles[0])[0],\n",
    "    fits.open(infiles[1])[0],\n",
    "    fits.open(infiles[2])[0],\n",
    "    fits.open(infiles[3])[0],\n",
    "    fits.open(infiles[4])[0],\n",
    "    fits.open(infiles[5])[0],\n",
    "    fits.open(infiles[6])[0],\n",
    "    fits.open(infiles[7])[0],\n",
    "    fits.open(infiles[8])[0],\n",
    "    fits.open(infiles[9])[0],\n",
    "    fits.open(infiles[10])[0],\n",
    "    fits.open(infiles[11])[0],\n",
    "]\n",
    "headers = [\n",
    "    hdulists[0].header,\n",
    "    hdulists[1].header,\n",
    "    hdulists[2].header,\n",
    "    hdulists[3].header,\n",
    "    hdulists[4].header,\n",
    "    hdulists[5].header,\n",
    "    hdulists[6].header,\n",
    "    hdulists[7].header,\n",
    "    hdulists[8].header,\n",
    "    hdulists[9].header,\n",
    "    hdulists[10].header,\n",
    "    hdulists[11].header,\n",
    "]\n",
    "bkg_hdus = [\n",
    "    fits.open(skybgfiles[0])[0],\n",
    "    fits.open(skybgfiles[1])[0],\n",
    "    fits.open(skybgfiles[2])[0],\n",
    "    fits.open(skybgfiles[3])[0],\n",
    "    fits.open(skybgfiles[4])[0],\n",
    "    fits.open(skybgfiles[5])[0],\n",
    "    fits.open(infiles[6])[0],\n",
    "    fits.open(skybgfiles[7])[0],\n",
    "    fits.open(skybgfiles[8])[0],\n",
    "    fits.open(skybgfiles[9])[0],\n",
    "    fits.open(skybgfiles[10])[0],\n",
    "    fits.open(skybgfiles[11])[0],\n",
    "]\n",
    "\n",
    "# grab the WCS of the mosaics\n",
    "wcs_infos = [\n",
    "    wcs.WCS(hdulists[0]),\n",
    "    wcs.WCS(hdulists[1]),\n",
    "    wcs.WCS(hdulists[2]),\n",
    "    wcs.WCS(hdulists[3]),\n",
    "    wcs.WCS(hdulists[4]),\n",
    "    wcs.WCS(hdulists[5]),\n",
    "    wcs.WCS(hdulists[6]),\n",
    "    wcs.WCS(hdulists[7]),\n",
    "    wcs.WCS(hdulists[8]),\n",
    "    wcs.WCS(hdulists[9]),\n",
    "    wcs.WCS(hdulists[10]),\n",
    "    wcs.WCS(hdulists[11]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use IRSA's firefly to display image and overlay table\n",
    "# just so we know what the data looks like\n",
    "fc = FireflyClient.make_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give firefly one of the mosaics we are using here\n",
    "imval = fc.upload_file(infiles[0])\n",
    "status = fc.show_fits(file_on_server=imval, plot_id=\"IRAC_ch1\", title=\"IRAC ch1\")\n",
    "\n",
    "# and give firefly a table\n",
    "# first convert to fits table from pandas\n",
    "t_df = Table.from_pandas(df)\n",
    "tablename = \"../data/IRAC/COSMOS_table.fits\"\n",
    "t_df.write(tablename, overwrite=\"True\")\n",
    "file = fc.upload_file(tablename)\n",
    "status = fc.show_table(file, tbl_id=\"df\", title=\"COSMOS catalog\")\n",
    "\n",
    "# this should work, and is simpler, but isn't working.\n",
    "# file_table = ffplt.upload_table(t_df, title = 'COSMOS catalog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "This view will not display all of the catalog rows overlaid on the image.  To do that, narrow down the catalog size by filtering on the catalog inside of the IRSA Viewer web browser.  Documentation for how to interacto with IRSA Viewer is here: https://irsa.ipac.caltech.edu/onlinehelp/irsaviewer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function to do the forced photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_instrflux(band, ra, dec, stype, ks_flux_aper2, g_band):\n",
    "    \"\"\"\n",
    "    calculate instrumental fluxes and uncertainties for four IRAC bands\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    band: int\n",
    "        integer in [0, 1, 2, 3,4, 5] for the four IRAC bands and two Galex bands\n",
    "    ra, dec: float or double\n",
    "        celestial coordinates for measuring photometry\n",
    "    stype: int\n",
    "        0, 1, 2, -9 for star, galaxy, x-ray source\n",
    "    ks_flux_aper_2: float\n",
    "        flux in aperture 2\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    outband: int\n",
    "        reflects input band for identification purposes\n",
    "    flux: float\n",
    "        measured flux in microJansky, NaN if unmeasurable\n",
    "    unc: float\n",
    "        measured uncertainty in microJansky, NaN if not able to estimate\n",
    "    \"\"\"\n",
    "    prf = prfs[band]\n",
    "    infile = infiles[g_band]\n",
    "    hdr = headers[g_band]\n",
    "    cutout_width = cutout_width_list[band]\n",
    "    mosaic_pix_scale = mosaic_pix_scale_list[band]\n",
    "    flux_conv = flux_conv_list[band]\n",
    "    background_method = background_method_list[band]\n",
    "\n",
    "    # tractor doesn't need the entire image, just a small region around the object of interest\n",
    "    subimage, nodata_param, x1, y1, subimage_wcs = extract_cutout(\n",
    "        ra, dec, cutout_width, mosaic_pix_scale, hdulists[g_band], wcs_infos[g_band]\n",
    "    )\n",
    "    # for the Galex images, also need to make a background cutout image\n",
    "    if background_method == \"skybg\":\n",
    "        bgsubimage, bgnodata_param, bgx1, bgy1, bgimage_wcs = extract_cutout(\n",
    "            ra, dec, cutout_width, mosaic_pix_scale, hdulists[g_band], wcs_infos[g_band]\n",
    "        )\n",
    "\n",
    "    # catch errors in making the cutouts\n",
    "    if nodata_param == False:  # meaning we have data in the cutout\n",
    "\n",
    "        # set up the source list by finding neighboring sources\n",
    "        objsrc, nconfsrcs = find_nconfsources(\n",
    "            ra, dec, stype, ks_flux_aper2, x1, y1, cutout_width, subimage_wcs, df\n",
    "        )\n",
    "\n",
    "        # measure sky noise and mean level\n",
    "        # suppress warnings about nans in the calculation\n",
    "        if background_method == \"image\":\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                skymean, skymedian, skynoise = sigma_clipped_stats(subimage, sigma=3.0)\n",
    "        if background_method == \"skybg\":\n",
    "            skymean, skymedian, skynoise = sigma_clipped_stats(bgsubimage, sigma=3.0)\n",
    "\n",
    "        # make the tractor image\n",
    "        tim = Image(\n",
    "            data=subimage,\n",
    "            invvar=np.ones_like(subimage) / skynoise**2,\n",
    "            psf=PixelizedPSF(prf),\n",
    "            wcs=NullWCS(),\n",
    "            photocal=NullPhotoCal(),\n",
    "            sky=ConstantSky(skymean),\n",
    "        )\n",
    "\n",
    "        # make tractor object combining tractor image and source list\n",
    "        tractor = Tractor([tim], objsrc)  # [src]\n",
    "\n",
    "        # freeze the parameters we don't want tractor fitting\n",
    "        tractor.freezeParam(\"images\")  # now fits 2 positions and flux\n",
    "        # tractor.freezeAllRecursive()#only fit for flux\n",
    "        # tractor.thawPathsTo('brightness')\n",
    "\n",
    "        # run the tractor optimization (do forced photometry)\n",
    "        # Take several linearized least squares steps\n",
    "        fit_fail = False\n",
    "        try:\n",
    "            tr = 0\n",
    "            with suppress_stdout():\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", \".*divide by zero.*\")\n",
    "                    # warnings.simplefilter('ignore')\n",
    "                    for tr in range(20):\n",
    "                        dlnp, X, alpha, flux_var = tractor.optimize(variance=True)\n",
    "                        # print('dlnp',dlnp)\n",
    "                        if dlnp < 1e-3:\n",
    "                            break\n",
    "        # catch exceptions and bad fits\n",
    "        except:\n",
    "            fit_fail = True\n",
    "\n",
    "        # record the photometry results\n",
    "        if fit_fail:\n",
    "            # tractor fit failed\n",
    "            # set flux and uncertainty as nan and move on\n",
    "            return (band, np.nan, np.nan)\n",
    "        elif flux_var is None:\n",
    "            # fit worked, but flux variance did not get reported\n",
    "            params_list = objsrc[0].getParamNames()\n",
    "            bindex = params_list.index(\"brightness.Flux\")\n",
    "            flux = objsrc[0].getParams()[bindex]\n",
    "            # convert to microjanskies\n",
    "            microJy_flux = flux * flux_conv\n",
    "            return (band, microJy_flux, np.nan)\n",
    "        else:\n",
    "            # fit and variance worked\n",
    "            params_list = objsrc[0].getParamNames()\n",
    "            bindex = params_list.index(\"brightness.Flux\")\n",
    "            flux = objsrc[0].getParams()[bindex]\n",
    "\n",
    "            # determine flux uncertainty\n",
    "            # which value of flux_var is for the flux variance?\n",
    "            fv = ((nconfsrcs + 1) * 3) - 1  # assumes we are fitting positions and flux\n",
    "            # fv = ((nconfsrcs+1)*1) - 1  #assumes we are fitting only flux\n",
    "\n",
    "            tractor_std = np.sqrt(flux_var[fv])\n",
    "\n",
    "            # convert to microjanskies\n",
    "            microJy_flux = flux * flux_conv\n",
    "            microJy_unc = tractor_std * flux_conv\n",
    "            return (band, microJy_flux, microJy_unc)\n",
    "\n",
    "    else:\n",
    "        return (band, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate forced photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straightforward but slow method\n",
    "no longer in use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "#do the calculation without multiprocessing for benchmarking\n",
    "\n",
    "#make a copy for parallel computation\n",
    "pl_df = df.copy(deep=True)\n",
    "\n",
    "t0 = time.time()\n",
    "#for each object\n",
    "for row in df.itertuples():\n",
    "    #for each band\n",
    "    for band in range(6):\n",
    "        #measure the flux with tractor\n",
    "        outband, flux, unc = calc_instrflux(band, row.ra, row.dec, row.type, row.ks_flux_aper2)\n",
    "        #put the results back into the dataframe\n",
    "        df.loc[row.Index, 'ch{:d}flux'.format(outband+1)] = flux\n",
    "        df.loc[row.Index, 'ch{:d}flux_unc'.format(outband+1)] = unc\n",
    "        #print(row.ra, row.dec, row.type, row.ks_flux_aper2, band+1,\n",
    "        #      outband, flux, unc)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "#10,000 sources took 1.5 hours with this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now measure the flux using all of the processors for optimizing speed on large datasets\n",
    "Parallelization: we can either interate over the rows of the dataframe and run the four bands in parallel; or we could zip together the row index, band, ra, dec, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist = []\n",
    "g_band = 4\n",
    "for row in df.itertuples():\n",
    "    for band in range(6):\n",
    "        if band < 4:\n",
    "            g_band = band\n",
    "        if band == 4:  # galex NUV: need to figure out which galex mosaic to use\n",
    "            choices = {\n",
    "                \"COSMOS_01\": 4,\n",
    "                \"COSMOS_02\": 6,\n",
    "                \"COSMOS_03\": 8,\n",
    "                \"COSMOS_04\": 10,\n",
    "            }\n",
    "            g_band = choices.get(row.galex_image, \"default\")\n",
    "        if band == 5:  # galex FUV: need to figure out which galex mosaic to use\n",
    "            choices = {\n",
    "                \"COSMOS_01\": 5,\n",
    "                \"COSMOS_02\": 7,\n",
    "                \"COSMOS_03\": 9,\n",
    "                \"COSMOS_04\": 11,\n",
    "            }\n",
    "            g_band = choices.get(row.galex_image, \"default\")\n",
    "        paramlist.append(\n",
    "            [row.Index, band, row.ra, row.dec, row.type, row.ks_flux_aper2, g_band]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this out on one object\n",
    "calc_instrflux(\n",
    "    paramlist[0][1],\n",
    "    paramlist[0][2],\n",
    "    paramlist[0][3],\n",
    "    paramlist[0][4],\n",
    "    paramlist[0][5],\n",
    "    paramlist[0][6],\n",
    ")\n",
    "\n",
    "# same thing, different syntax\n",
    "# calc_instrflux(*paramlist[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper to measure the photometry on a single object, single band\n",
    "def calculate_flux(args):\n",
    "    \"\"\"Calculate flux.\"\"\"\n",
    "    f = calc_instrflux\n",
    "    val = f(*args[1:])\n",
    "    return (args[0], val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Here is where the multiprocessing work gets done\n",
    "t2 = time.time()\n",
    "outputs = []\n",
    "with concurrent.futures.ProcessPoolExecutor(24) as executor:\n",
    "    for result in executor.map(calculate_flux, paramlist):\n",
    "        # print(result)\n",
    "        df.loc[result[0], \"ch{:d}flux\".format(result[1][0] + 1)] = result[1][1]\n",
    "        df.loc[result[0], \"ch{:d}flux_unc\".format(result[1][0] + 1)] = result[1][1]\n",
    "        outputs.append(result)\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Serial calculation took {:.2f} seconds'.format((t1 - t0)))\n",
    "print(\"Parallel calculation took {:.2f} seconds\".format((t3 - t2)))\n",
    "# print('Speedup is {:.2f}'.format((t1 - t0) / (t3 - t2)))\n",
    "\n",
    "# speedup was factors of 10 - 12 for 400 - 10000 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of non-zero ch1 fluxes\n",
    "# print('Serial calculation: number of ch1 fluxes filled in =',\n",
    "#      np.sum(df.ch1flux > 0))\n",
    "print(\"Parallel calculation: number of ch1 fluxes filled in =\", np.sum(df.ch1flux > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to call the galex flux columns ch5 and ch6\n",
    "# fix that by renaming them now\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"ch5flux\": \"nuvflux\",\n",
    "        \"ch5flux_unc\": \"nuvflux_unc\",\n",
    "        \"ch6flux\": \"fuvflux\",\n",
    "        \"ch6flux_unc\": \"fuvflux_unc\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# pl_df.rename(columns={'ch5flux':'nuvflux', 'ch5flux_unc':'nuvflux_unc','ch6flux':'fuvflux', 'ch6flux_unc':'fuvflux_unc'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting to confirm photometry results against COSMOS 2015 catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# plot tractor fluxes vs. catalog splash fluxes\n",
    "# should see a straightline with a slope of 1\n",
    "# using sns regplot which plots both the data and a linear regression model fit\n",
    "# this plotting tool is for visualization and not statistics, so I don't have rigorous slopes from it.\n",
    "\n",
    "# setup to plot\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2)\n",
    "fluxmax = 200\n",
    "ymax = 100\n",
    "xmax = 100\n",
    "# ch1\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry\n",
    "df_tractor = df[(df.splash_1_flux > 0) & (df.splash_1_flux < fluxmax)]  # 200\n",
    "# sns.regplot(data = df_tractor, x = \"splash_1_flux\", y = \"ch1flux\", ax = ax1, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"splash_1_flux\", y=\"ch1flux\", ax=ax1)\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax1.get_xlim(), ax1.get_ylim()]),  # min of both axes\n",
    "    np.max([ax1.get_xlim(), ax1.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax1.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax1.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"IRAC 3.6\",\n",
    ")\n",
    "ax1.set_ylim([0, ymax])\n",
    "ax1.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "# ch2\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry\n",
    "df_tractor = df[(df.splash_2_flux > 0) & (df.splash_2_flux < fluxmax)]\n",
    "# sns.regplot(data = df_tractor, x = \"splash_2_flux\", y = \"ch2flux\", ax = ax2, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"splash_2_flux\", y=\"ch2flux\", ax=ax2)\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax2.get_xlim(), ax2.get_ylim()]),  # min of both axes\n",
    "    np.max([ax2.get_xlim(), ax2.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax2.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax2.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"IRAC 4.5\",\n",
    ")\n",
    "ax2.set_ylim([0, ymax])\n",
    "ax2.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "# ch3\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry\n",
    "df_tractor = df[(df.splash_3_flux > 0) & (df.splash_3_flux < fluxmax)]\n",
    "\n",
    "# sns.regplot(data = df_tractor, x = \"splash_3_flux\", y = \"ch3flux\", ax = ax3, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"splash_3_flux\", y=\"ch3flux\", ax=ax3)\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax3.get_xlim(), ax3.get_ylim()]),  # min of both axes\n",
    "    np.max([ax3.get_xlim(), ax3.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax3.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax3.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"IRAC 5.8\",\n",
    ")\n",
    "ax3.set_ylim([0, ymax])\n",
    "ax3.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "# ch4\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry\n",
    "df_tractor = df[(df.splash_4_flux > 0) & (df.splash_4_flux < fluxmax)]\n",
    "\n",
    "# sns.regplot(data = df_tractor, x = \"splash_4_flux\", y = \"ch4flux\", ax = ax4, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"splash_4_flux\", y=\"ch4flux\", ax=ax4)\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax4.get_xlim(), ax4.get_ylim()]),  # min of both axes\n",
    "    np.max([ax4.get_xlim(), ax4.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax4.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax4.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"IRAC 8.0\",\n",
    ")\n",
    "ax4.set_ylim([0, ymax])\n",
    "ax4.set_xlim([0, xmax])\n",
    "\n",
    "# -------\n",
    "# nuv\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry while testing\n",
    "df_tractor = df[(df.flux_galex_nuv > 0) & (df.flux_galex_nuv < 20)]\n",
    "\n",
    "# sns.regplot(data = df_tractor, x = \"flux_galex_nuv\", y = \"nuvflux\", ax = ax5, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"flux_galex_nuv\", y=\"nuvflux\", ax=ax5)\n",
    "\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "# lims = [\n",
    "#    np.min([ax4.get_xlim(), ax4.get_ylim()]),  # min of both axes\n",
    "#    np.max([ax4.get_xlim(), ax4.get_ylim()]),  # max of both axes\n",
    "# ]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "# ax4.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax5.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"Galex NUV\",\n",
    ")\n",
    "ax5.set_yscale(\"log\")\n",
    "# -------\n",
    "# fuv\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry while testing\n",
    "df_tractor = df[(df.flux_galex_fuv > 0) & (df.flux_galex_fuv < 20)]\n",
    "\n",
    "# sns.regplot(data = df_tractor, x = \"flux_galex_fuv\", y = \"fuvflux\", ax = ax6, robust = True)\n",
    "sns.scatterplot(data=df_tractor, x=\"flux_galex_fuv\", y=\"fuvflux\", ax=ax6)\n",
    "\n",
    "\n",
    "# add a diagonal line with y = x\n",
    "# lims = [\n",
    "#    np.min([ax4.get_xlim(), ax4.get_ylim()]),  # min of both axes\n",
    "#    np.max([ax4.get_xlim(), ax4.get_ylim()]),  # max of both axes\n",
    "# ]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "# ax4.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax6.set(\n",
    "    xlabel=\"COSMOS 2015 flux ($\\mu$Jy)\",\n",
    "    ylabel=\"tractor flux ($\\mu$Jy)\",\n",
    "    title=\"Galex FUV\",\n",
    ")\n",
    "ax6.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "fig.set_size_inches(8, 12)\n",
    "\n",
    "# plt.savefig('flux_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tractor is working for IRAC; Comparison of tractor derived fluxes with COSMOS 2015 fluxes for all four Spitzer IRAC channels.  Blue points represent each object from the subset of the COSMOS 2015 catalog.  The blue line is a linear regression robust fit to the data with uncertainties shown as the light blue wedge.  The black line is a y = x line plotted to guide the eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe with the forced photometry\n",
    "# df.to_pickle('../data/COSMOS_15arcmin.pkl')\n",
    "\n",
    "# or read it back in\n",
    "# df = pd.read_pickle('../data/COSMOS_15arcmin_FUV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross match this newly built catalog with an X-ray catalog\n",
    "We are using nway as the tool to do the cross match Salvato et al. 2017.\n",
    "nway expects input as two fits table files and outputs a third table file with all the possible matches and their probabilities of being the correct match.  We then sort that catalog and take only the best matches to be the true matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get an X-ray catalog from Heasarc\n",
    "heasarc = Heasarc()\n",
    "table = heasarc.query_mission_list()\n",
    "mask = table[\"Mission\"] == \"CHANDRA\"\n",
    "chandratable = table[mask]\n",
    "\n",
    "# tell me which tables exist there\n",
    "# chandratable.pprint(max_lines = 200, max_width = 130)\n",
    "\n",
    "# want ccosmoscat\n",
    "mission = \"ccosmoscat\"\n",
    "# coords already defined above where I pull the original COSMOS catalog\n",
    "ccosmoscat_rad = 1  # radius of chandra cosmos catalog\n",
    "ccosmoscat = heasarc.query_region(\n",
    "    coords, mission=mission, radius=\"1 degree\", resultmax=5000, fields=\"ALL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astropy doesn't recognize capitalized units\n",
    "# so there will be some warnings here on writing out the file, but we can safely ignore those\n",
    "\n",
    "# need to make the chandra catalog into a fits table\n",
    "# and needs to include area of the survey.\n",
    "ccosmoscat.meta[\"NAME\"] = \"CHANDRA\"\n",
    "ccosmoscat.meta[\"SKYAREA\"] = float(1.0)  # in square degrees\n",
    "\n",
    "# also need an 'ID' column\n",
    "ccosmoscat[\"ID\"] = range(1, len(ccosmoscat) + 1)\n",
    "ccosmoscat.write(\"../data/Chandra/COSMOS_chandra.fits\", overwrite=\"True\")\n",
    "\n",
    "# above isn't working to get the name into the table\n",
    "# try this\n",
    "nway_write_header(\n",
    "    \"../data/Chandra/COSMOS_chandra.fits\", \"CHANDRA\", float(ccosmoscat_rad**2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also need to transform the main pandas dataframe into fits table for nway\n",
    "\n",
    "# make an index column for tracking later\n",
    "df[\"ID\"] = range(1, len(df) + 1)\n",
    "\n",
    "# need this to be a fits table and needs to include area of the survey.\n",
    "df_table = Table.from_pandas(df)\n",
    "df_table\n",
    "df_table.meta[\"NAME\"] = \"OPT\"\n",
    "df_table.meta[\"SKYAREA\"] = float((2 * rad_in_arcmin / 60) ** 2)  # catalog\n",
    "\n",
    "df_table.write(\"../data/multiband_phot.fits\", overwrite=\"True\")\n",
    "\n",
    "# above isn't working to get the name into the table\n",
    "# try this\n",
    "nway_write_header(\n",
    "    \"../data/multiband_phot.fits\", \"OPT\", float((2 * rad_in_arcmin / 60) ** 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nway calling sequence\n",
    "!nway.py '../data/Chandra/COSMOS_chandra.fits' :ERROR_RADIUS '../data/multiband_phot.fits' 0.1 --out=../data/Chandra/chandra_multiband.fits --radius 15 --prior-completeness 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the cross match results and merge them back into main pandas dataframe\n",
    "\n",
    "# read in the nway matched catalog\n",
    "xmatch = Table.read(\"../data/Chandra/chandra_multiband.fits\", hdu=1)\n",
    "df_xmatch = xmatch.to_pandas()\n",
    "\n",
    "# manual suggests that p_i should be greater than 0.1 for a pure catalog.\n",
    "# ok, so the matched catalog has multiple optical associations for some of the XMM detections.\n",
    "# simplest thing to do is only keep match_flag = 1\n",
    "matched = df_xmatch.loc[(df_xmatch[\"p_i\"] >= 0.1) & df_xmatch[\"match_flag\"] == 1]\n",
    "\n",
    "# merge this info back into the df_optical dataframe.\n",
    "merged = pd.merge(df, matched, \"outer\", left_on=\"ID\", right_on=\"OPT_ID\")\n",
    "\n",
    "# will need to delete unnecessary rows that matched has duplicated from pl_df\n",
    "# for col in merged.columns:\n",
    "#    print(col)\n",
    "\n",
    "# remove all the rows which start with \"OPT\" because they are duplications of the original catalog\n",
    "merged = merged.loc[:, ~merged.columns.str.startswith(\"OPT\")]\n",
    "\n",
    "# somehow the matching is giving negative fluxes in the band where there is no detection\n",
    "# if there is a detection in the other band\n",
    "# clean that up to make those negative fluxes = 0\n",
    "\n",
    "merged.loc[merged[\"flux_chandra_2_10\"] < 0, \"flux_chandra_2_10\"] = 0\n",
    "merged.loc[merged[\"flux_chandra_05_2\"] < 0, \"flux_chandra_05_2\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many CHandra sources are there?\n",
    "\n",
    "# make a new column which is a bool of existing chandra measurements\n",
    "merged[\"chandra_detect\"] = 0\n",
    "merged.loc[merged.CHANDRA_FLUX > 0, \"chandra_detect\"] = 1\n",
    "\n",
    "# make one for Galex too\n",
    "merged[\"galex_detect\"] = 0\n",
    "merged.loc[merged.flux_galex_nuv > 0, \"galex_detect\"] = 1\n",
    "\n",
    "\n",
    "print(\"number of Chandra detections =\", np.sum(merged.chandra_detect > 0))\n",
    "print(\"number of Galex detections =\", np.sum(merged.galex_detect > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting to confirm photometry results against COSMOS 2015 catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "# first shrink the dataframe to only those rows where I have tractor photometry while testing\n",
    "merged_small = merged[(merged.chandra_detect >= 0)]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=merged_small, x=\"CHANDRA_HB_FLUX\", y=\"flux_chandra_2_10\", ax=ax2\n",
    ")  # , robust = True)#scatterplot\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax2.get_xlim(), ax2.get_ylim()]),  # min of both axes\n",
    "    np.max([ax2.get_xlim(), ax2.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax2.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax2.set(\n",
    "    xlabel=\"COSMOS (erg/s/cm2)\",\n",
    "    ylabel=\"nway matched (erg/s/cm2)\",\n",
    "    title=\"Chandra HB (2 - 10)\",\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=merged_small, x=\"CHANDRA_SB_FLUX\", y=\"flux_chandra_05_2\", ax=ax1\n",
    ")  # , robust = True)#scatterplot\n",
    "# add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax1.get_xlim(), ax1.get_ylim()]),  # min of both axes\n",
    "    np.max([ax1.get_xlim(), ax1.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax1.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "ax1.set(\n",
    "    xlabel=\"COSMOS (erg/s/cm2)\",\n",
    "    ylabel=\"nway matched(erg/s/cm2)\",\n",
    "    title=\"Chandra SB (05 - 2)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some plots which show off the results and facilitate science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC color color plots akin to Lacy et al. 2004\n",
    "# overplot galex sources\n",
    "# overplot xray sources\n",
    "\n",
    "# first select on 24 micron\n",
    "merged_24 = merged[(merged.flux_24 >= 0)]\n",
    "\n",
    "# negative Galex fluxes are causing problems\n",
    "merged_24.loc[merged_24.fuvflux < 0, \"fuvflux\"] = 0\n",
    "merged_24.loc[merged_24.nuvflux < 0, \"nuvflux\"] = 0\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "merged_24[\"F5.8divF3.6\"] = merged_24.ch3flux / merged_24.ch1flux\n",
    "merged_24[\"F8.0divF4.5\"] = merged_24.ch4flux / merged_24.ch2flux\n",
    "\n",
    "merged_allirac = merged_24[\n",
    "    (merged_24[\"F8.0divF4.5\"] > 0) & (merged_24[\"F5.8divF3.6\"] > 0)\n",
    "]\n",
    "\n",
    "# plot all the points\n",
    "sns.scatterplot(data=merged_allirac, x=\"F5.8divF3.6\", y=\"F8.0divF4.5\", ax=ax, alpha=0.5)\n",
    "\n",
    "# plot only those points with Galex detections\n",
    "galex_detect = merged_allirac[merged_allirac.galex_detect > 0]\n",
    "sns.scatterplot(data=galex_detect, x=\"F5.8divF3.6\", y=\"F8.0divF4.5\", ax=ax, alpha=0.5)\n",
    "\n",
    "# plot only those points with chandra detections\n",
    "chandra_detect = merged_allirac[merged_allirac.chandra_detect > 0]\n",
    "sns.scatterplot(data=chandra_detect, x=\"F5.8divF3.6\", y=\"F8.0divF4.5\", ax=ax)\n",
    "\n",
    "\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set_ylim([0.1, 10])\n",
    "ax.set_xlim([0.1, 10])\n",
    "\n",
    "ax.set(xlabel=\"log F5.8/F3.6\", ylabel=\"log F8.0/F4.5\")\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# apparently there is a known bug in mpld3 that it doesn't work with log scaled plots\n",
    "# mpld3.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UV IR color color plot akin to Bouquin et al. 2015\n",
    "fig, ax = plt.subplots()\n",
    "merged[\"FUV-NUV\"] = merged.mag_galex_fuv - merged.mag_galex_nuv\n",
    "merged[\"NUV-3.6\"] = merged.mag_galex_nuv - merged.splash_1_mag\n",
    "\n",
    "\n",
    "# plot all the points\n",
    "# sns.scatterplot(data = merged, x = 'NUV-3.6', y = 'FUV-NUV',\n",
    "#                 ax = ax, alpha = 0.5)\n",
    "\n",
    "# plot only those points with Galex detections\n",
    "galex_detect = merged[merged.galex_detect > 0]\n",
    "sns.kdeplot(\n",
    "    data=galex_detect, x=\"NUV-3.6\", y=\"FUV-NUV\", ax=ax, fill=True, levels=15\n",
    ")  # scatterplot , alpha = 0.5\n",
    "\n",
    "# plot only those points with chandra detections\n",
    "# now with color coding Chandra sources by hardness ratio a la Moutard et al. 2020\n",
    "chandra_detect = merged[merged.chandra_detect > 0]\n",
    "sns.scatterplot(\n",
    "    data=chandra_detect,\n",
    "    x=\"NUV-3.6\",\n",
    "    y=\"FUV-NUV\",\n",
    "    ax=ax,\n",
    "    hue=\"CHANDRA_HARDNESS_RATIO\",\n",
    "    palette=\"flare\",\n",
    ")\n",
    "\n",
    "# whew that legend for the hue is terrible\n",
    "# try making it into a colorbar outside the plot instead\n",
    "norm = plt.Normalize(\n",
    "    merged[\"CHANDRA_HARDNESS_RATIO\"].min(), merged[\"CHANDRA_HARDNESS_RATIO\"].max()\n",
    ")\n",
    "sm = plt.cm.ScalarMappable(cmap=\"flare\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm)\n",
    "\n",
    "# ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set_ylim([-0.5, 3.5])\n",
    "ax.set_xlim([-1, 7])\n",
    "\n",
    "ax.set(xlabel=\"NUV - [3.6]\", ylabel=\"FUV - NUV\")\n",
    "# plt.legend([],[], frameon=False)\n",
    "\n",
    "# fig.savefig(\"../data/color_color.png\")\n",
    "mpld3.display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend the works of Bouquin et al. 2015 and Moutard et al. 2020 by showing a GALEX - Spitzer color color diagram over plotted with Chandra detections.  Blue galaxies in these colors are generated by O and B stars and so must currently be forming stars. We find a tight blue cloud in this color space identifying those star forming galaxies.  Galaxies off of the blue cloud have had their star formation quenched, quite possibly by the existence of an AGN through removal of the gas reservoir required for star formation.  Chandra detected galaxies host AGN, and while those are more limited in number, can be shown here to be a hosted by all kinds of galaxies, including quiescent galaxies which would be in the upper right of this plot.  This likely implies that AGN are indeed involved in quenching star formation.  Additionally, we show the Chandra hardness ratio (HR) color coded according to the vertical color bar on the right side of the plot.  HR is defined as (H-S)/ (H+S) where H and S are the hard[2-10KeV] and soft[0.5-2KeV] bands of Chandra.  Those AGN with higher hardness ratios have their soft x-ray bands heavily obscured and appear to reside preferentially toward the quiescent galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential plot ideas\n",
    "# salim et al. 2014 serbia astronomical journal\n",
    "# (3.6 magniutde) vs. (NUV - 3.6)\n",
    "\n",
    "\n",
    "# match to cosmos catalog\n",
    "# get the galex fluxes then make the green valley plots of bouquin et al,\n",
    "# then overplot x-ray\n",
    "\n",
    "# second option\n",
    "# match to cosmos for 24 microns and make lacy et al. plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in merged.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
